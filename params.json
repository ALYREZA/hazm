{"name":"Hazm","tagline":"Python library for digesting Persian text.","body":"Hazm\r\n====\r\n\r\nPython library for digesting Persian text.\r\n\r\n+ NLTK compatible\r\n+ Supports Python 3.3 and 2.7\r\n\r\n## Usage\r\n\r\n```python\r\n\r\n>>> from hazm import Normalizer\r\n>>> normalizer = Normalizer()\r\n>>> normalizer.normalize('اصلاح نويسه ها و استفاده از نیم‌فاصله پردازش را آسان مي كند')\r\n'اصلاح نویسه‌ها و استفاده از نیم‌فاصله پردازش را آسان می‌کند'\r\n\r\n>>> from hazm import sent_tokenize, word_tokenize\r\n>>> sent_tokenize('ما هم برای وصل کردن آمدیم! ولی برای پردازش، جدا بهتر نیست؟')\r\n['ما هم برای وصل کردن آمدیم!', 'ولی برای پردازش، جدا بهتر نیست؟']\r\n>>> word_tokenize('ولی برای پردازش، جدا بهتر نیست؟')\r\n['ولی', 'برای', 'پردازش', '،', 'جدا', 'بهتر', 'نیست', '؟']\r\n\r\n>>> from hazm import Stemmer, Lemmatizer\r\n>>> stemmer = Stemmer()\r\n>>> stemmer.stem('کتاب‌ها')\r\n'کتاب'\r\n>>> lemmatizer = Lemmatizer()\r\n>>> lemmatizer.lemmatize('می‌روم')\r\n'رفت#رو'\r\n\r\n```\r\n\r\n## Installation\r\n\r\n\tpip install hazm\r\n\r\n## Tests\r\n\r\n\tpython3 -m doctest README.md\r\n\tpython3 -m hazm.{module}\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}